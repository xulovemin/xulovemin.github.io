[{"title":"flink_spark_standalone","date":"2021-04-30T09:43:22.000Z","path":"2021/04/30/flink-spark-standalone/","text":"启动 docker-compose.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103version: \"3\"services: namenode: image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8 container_name: namenode restart: always ports: - 9870:9870 - 9000:9000 volumes: - hadoop_namenode:/hadoop/dfs/name environment: - CLUSTER_NAME=test env_file: - ./hadoop.env datanode: image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8 container_name: datanode restart: always ports: - 9864:9864 volumes: - hadoop_datanode:/hadoop/dfs/data environment: SERVICE_PRECONDITION: \"namenode:9870\" env_file: - ./hadoop.env spark-master: image: bde2020/spark-master:2.2.0-hadoop2.8-hive-java8 container_name: spark-master restart: always ports: - 8080:8080 - 7077:7077 - 4040:4040 - 10000:10000 - 18080:18080 env_file: - ./hadoop.env volumes: - ./hive-site.xml:/spark/conf/hive-site.xml - ./spark-defaults.conf:/spark/conf/spark-defaults.conf spark-worker: image: bde2020/spark-worker:2.2.0-hadoop2.8-hive-java8 container_name: spark-worker restart: always ports: - 8081:8081 env_file: - ./hadoop.env environment: - \"SPARK_MASTER=spark://spark-master:7077\" jobmanager: image: myflink container_name: jobmanager ports: - \"8082:8081\" command: jobmanager environment: - | FLINK_PROPERTIES= jobmanager.rpc.address: jobmanager classloader.resolve-order: parent-first volumes: - ./hive-site.xml:/opt/hive_conf/hive-site.xml - ./sql-client-defaults.yaml:/opt/flink/conf/sql-client-defaults.yaml taskmanager: image: myflink container_name: taskmanager depends_on: - jobmanager command: taskmanager environment: - | FLINK_PROPERTIES= jobmanager.rpc.address: jobmanager taskmanager.numberOfTaskSlots: 12 hive-metastore: container_name: hive-metastore image: bde2020/hive:2.3.2 restart: always env_file: - ./hadoop.env command: /opt/hive/bin/hive --service metastore environment: SERVICE_PRECONDITION: \"namenode:9870 datanode:9864 postgresql:5432\" postgresql: container_name: postgresql image: bde2020/hive-metastore-postgresql:2.3.0 volumes: - pgdata:/var/lib/postgresql/datavolumes: hadoop_namenode: hadoop_datanode: pgdata: Dockerfile 12FROM flink:1.12-scala_2.11-java8COPY ./sql-lib /opt/flink/sql-lib hadoop.env 12345678910111213141516HIVE_SITE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://postgresql/metastoreHIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName=org.postgresql.DriverHIVE_SITE_CONF_javax_jdo_option_ConnectionUserName=hiveHIVE_SITE_CONF_javax_jdo_option_ConnectionPassword=hiveHIVE_SITE_CONF_datanucleus_autoCreateSchema=falseHIVE_SITE_CONF_hive_metastore_uris=thrift://hive-metastore:9083CORE_CONF_fs_defaultFS=hdfs://namenode:9000CORE_CONF_hadoop_http_staticuser_user=rootCORE_CONF_hadoop_proxyuser_hue_hosts=*CORE_CONF_hadoop_proxyuser_hue_groups=*CORE_CONF_io_compression_codecs=org.apache.hadoop.io.compress.SnappyCodecHDFS_CONF_dfs_webhdfs_enabled=trueHDFS_CONF_dfs_permissions_enabled=falseHDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false hive-site.xml 123456789&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;thrift://hive-metastore:9083&lt;/value&gt; &lt;description&gt;Thrift URI for remote metastore.Used by metastore client to connect to remote metastore&lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; spark-defaults.conf 123spark.master spark://spark-master:7077spark.eventLog.enabled truespark.eventLog.dir hdfs://namenode:9000/history sql-client-defaults.yaml 1234567891011121314151617181920212223242526tables: []functions: []catalogs: - name: myhive type: hive hive-conf-dir: /opt/hive_conf/ default-database: defaultexecution: planner: blink type: streaming time-characteristic: event-time periodic-watermarks-interval: 200 result-mode: table max-table-result-rows: 1000000 max-parallelism: 128 min-idle-state-retention: 0 max-idle-state-retention: 0 current-catalog: myhive current-database: defaultdeployment: response-timeout: 5000 gateway-address: \"\" gateway-port: 0 说明 hadoop只用hdfs作为存储不启用yarn flink需要新打一个镜像，将需要的jar包拷贝进去flink-connector-jdbc_2.11-1.12.0.jar、flink-shaded-hadoop-2-uber-2.8.3-10.0.jar、flink-sql-connector-hive-2.3.6_2.11-1.12.0.jar、mysql-connector-java-8.0.23.jar、ojdbc6-12.1.0.1-atlassian-hosted.jar，flink-sql链接库所需要的 spark需要下载spark-hive版本，支持spark-sql hive还可以用老版本作为元数据管理 spark提交任务 1/spark/bin/spark-submit --master spark://spark-master:7077 --class org.apache.spark.examples.SparkPi /spark/examples/jars/spark-examples_2.11-2.2.0.jar spark可以启动beeline服务来供给外部使用hivejdbc链接 1/spark/sbin/start-thriftserver.sh --master spark://spark-master:7077 spark启动history 1/spark/sbin/start-history-server.sh hdfs://namenode:9000/history flink配置完spark-default和sql-client配置就可以使用flink-sql了 1/opt/flink/bin/sql-client.sh embedded -l ./sql-lib/ 可以直接从hive中查询数据，提交到flink集群上面跑了"},{"title":"flinkOnYarn","date":"2021-04-30T09:25:57.000Z","path":"2021/04/30/flinkOnYarn/","text":"启动 docker-compose.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364version: \"3\"services: namenode: image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8 container_name: namenode restart: always ports: - 9870:9870 environment: - CLUSTER_NAME=test env_file: - ./hadoop.env datanode: image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8 container_name: datanode restart: always ports: - 9864:9864 environment: SERVICE_PRECONDITION: \"namenode:9870\" env_file: - ./hadoop.env resourcemanager: image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8 container_name: resourcemanager restart: always ports: - 8088:8088 environment: SERVICE_PRECONDITION: \"namenode:9000 namenode:9870 datanode:9864\" env_file: - ./hadoop.env nodemanager: image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8 container_name: nodemanager restart: always ports: - 8042:8042 environment: SERVICE_PRECONDITION: \"namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088\" env_file: - ./hadoop.env historyserver: image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8 container_name: historyserver restart: always ports: - 8188:8188 environment: SERVICE_PRECONDITION: \"namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088\" env_file: - ./hadoop.env flink-client: image: flink:yarn container_name: flink restart: always env_file: - ./hadoop.env command: tail -f /dev/null Dockerfile 12FROM bde2020/hadoop-base:2.0.0-hadoop3.2.1-java8COPY ./flink /opt/flink hadoop.env 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152HIVE_SITE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://postgresql/metastoreHIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName=org.postgresql.DriverHIVE_SITE_CONF_javax_jdo_option_ConnectionUserName=hiveHIVE_SITE_CONF_javax_jdo_option_ConnectionPassword=hiveHIVE_SITE_CONF_datanucleus_autoCreateSchema=falseHIVE_SITE_CONF_hive_metastore_uris=thrift://hive-metastore:9083CORE_CONF_fs_defaultFS=hdfs://namenode:9000CORE_CONF_hadoop_http_staticuser_user=rootCORE_CONF_hadoop_proxyuser_hue_hosts=*CORE_CONF_hadoop_proxyuser_hue_groups=*CORE_CONF_io_compression_codecs=org.apache.hadoop.io.compress.SnappyCodecHDFS_CONF_dfs_webhdfs_enabled=trueHDFS_CONF_dfs_permissions_enabled=falseHDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=falseYARN_CONF_yarn_log___aggregation___enable=trueYARN_CONF_yarn_log_server_url=http://historyserver:8188/applicationhistory/logs/YARN_CONF_yarn_resourcemanager_recovery_enabled=trueYARN_CONF_yarn_resourcemanager_store_class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStoreYARN_CONF_yarn_resourcemanager_scheduler_class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerYARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___mb=8192YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___vcores=4YARN_CONF_yarn_resourcemanager_fs_state___store_uri=/rmstateYARN_CONF_yarn_resourcemanager_system___metrics___publisher_enabled=trueYARN_CONF_yarn_resourcemanager_hostname=resourcemanagerYARN_CONF_yarn_resourcemanager_address=resourcemanager:8032YARN_CONF_yarn_resourcemanager_scheduler_address=resourcemanager:8030YARN_CONF_yarn_resourcemanager_resource__tracker_address=resourcemanager:8031YARN_CONF_yarn_timeline___service_enabled=trueYARN_CONF_yarn_timeline___service_generic___application___history_enabled=trueYARN_CONF_yarn_timeline___service_hostname=historyserverYARN_CONF_mapreduce_map_output_compress=trueYARN_CONF_mapred_map_output_compress_codec=org.apache.hadoop.io.compress.SnappyCodecYARN_CONF_yarn_nodemanager_resource_memory___mb=16384YARN_CONF_yarn_nodemanager_resource_cpu___vcores=8YARN_CONF_yarn_nodemanager_disk___health___checker_max___disk___utilization___per___disk___percentage=98.5YARN_CONF_yarn_nodemanager_remote___app___log___dir=/app-logsYARN_CONF_yarn_nodemanager_aux___services=mapreduce_shuffleYARN_CONF_yarn_nodemanager_pmem___check___enabled=falseYARN_CONF_yarn_nodemanager_vmem___check___enabled=falseMAPRED_CONF_mapreduce_framework_name=yarnMAPRED_CONF_mapred_child_java_opts=-Xmx4096mMAPRED_CONF_mapreduce_map_memory_mb=4096MAPRED_CONF_mapreduce_reduce_memory_mb=8192MAPRED_CONF_mapreduce_map_java_opts=-Xmx3072mMAPRED_CONF_mapreduce_reduce_java_opts=-Xmx6144mMAPRED_CONF_yarn_app_mapreduce_am_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/MAPRED_CONF_mapreduce_map_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/MAPRED_CONF_mapreduce_reduce_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/ 说明 flink、hadoop都可以下载最新版本 flink-shaded-hadoop-2-uber-2.8.3-10.0.jar需要拷贝到flink的lib目录里面 flink在这里也只作为一个客户端，使用yarn-session.sh -n 3 -s 3 -nm flink-sessiontest -d会直接在yarn上面启动flink集群-n,–container ：在yarn中启动container的个数，实质就是TaskManager的个数 -s,–slots ：每个TaskManager管理的Slot个数 -nm,–name :给当前的yarn-session(Flink集群)起一个名字 -d,–detached:后台独立模式启动，守护进程 -tm,–taskManagerMemory ：TaskManager的内存大小 单位：MB -jm,–jobManagerMemory ：JobManager的内 然后flink run -c com.stream.Test -yid application_1608200066135_0002 -p 15 xxx.jar 将任务提交到yarn运行 yarn启动flink集群会随机生成端口号才能查看flink的webui界面 查看日志也不是很方便"},{"title":"hadoop集群搭建","date":"2021-04-30T08:53:25.000Z","path":"2021/04/30/hadoop集群搭建/","text":"启动 docker-compose.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109version: \"3\"services: namenode: image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8 container_name: namenode restart: always ports: - 50070:50070 volumes: - hadoop_namenode:/hadoop/dfs/name environment: - CLUSTER_NAME=test env_file: - ./hadoop.env datanode: image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8 container_name: datanode restart: always ports: - 50075:50075 volumes: - hadoop_datanode:/hadoop/dfs/data environment: SERVICE_PRECONDITION: \"namenode:50070\" env_file: - ./hadoop.env resourcemanager: image: bde2020/hadoop-resourcemanager:2.0.0-hadoop2.7.4-java8 container_name: resourcemanager restart: always ports: - 8088:8088 environment: SERVICE_PRECONDITION: \"namenode:50070 datanode:50075\" env_file: - ./hadoop.env nodemanager: image: bde2020/hadoop-nodemanager:2.0.0-hadoop2.7.4-java8 container_name: nodemanager restart: always ports: - 8042:8042 environment: SERVICE_PRECONDITION: \"namenode:50070 datanode:50075 resourcemanager:8088\" env_file: - ./hadoop.env historyserver: image: bde2020/hadoop-historyserver:2.0.0-hadoop2.7.4-java8 container_name: historyserver restart: always ports: - 8188:8188 environment: SERVICE_PRECONDITION: \"namenode:50070 datanode:50075 resourcemanager:8088\" env_file: - ./hadoop.env hive-server: container_name: hive-server image: bde2020/hive:2.3.2 restart: always env_file: - ./hadoop.env environment: SERVICE_PRECONDITION: \"hive-metastore:9083\" ports: - 10000:10000 spark-master: image: bde2020/spark-master:2.2.0-hadoop2.8-hive-java8 container_name: spark-master restart: always ports: - 8080:8080 - 7077:7077 - 4040:4040 env_file: - ./hadoop.env volumes: - ./hive-site.xml:/spark/conf/hive-site.xml hive-metastore: container_name: hive-metastore image: bde2020/hive:2.3.2 restart: always env_file: - ./hadoop.env command: /opt/hive/bin/hive --service metastore environment: SERVICE_PRECONDITION: \"namenode:50070 datanode:50075 postgresql:5432\" ports: - 9083:9083 postgresql: container_name: postgresql image: bde2020/hive-metastore-postgresql:2.3.0 ports: - 5432:5432 volumes: - pgdata:/var/lib/postgresql/datavolumes: hadoop_namenode: hadoop_datanode: pgdata: hadoop.env 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253HIVE_SITE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://postgresql/metastoreHIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName=org.postgresql.DriverHIVE_SITE_CONF_javax_jdo_option_ConnectionUserName=hiveHIVE_SITE_CONF_javax_jdo_option_ConnectionPassword=hiveHIVE_SITE_CONF_datanucleus_autoCreateSchema=falseHIVE_SITE_CONF_hive_metastore_uris=thrift://hive-metastore:9083CORE_CONF_fs_defaultFS=hdfs://namenode:8020CORE_CONF_hadoop_http_staticuser_user=rootCORE_CONF_hadoop_proxyuser_hue_hosts=*CORE_CONF_hadoop_proxyuser_hue_groups=*CORE_CONF_io_compression_codecs=org.apache.hadoop.io.compress.SnappyCodecHDFS_CONF_dfs_webhdfs_enabled=trueHDFS_CONF_dfs_permissions_enabled=falseHDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=falseYARN_CONF_yarn_log___aggregation___enable=trueYARN_CONF_yarn_log_server_url=http://historyserver:8188/applicationhistory/logs/YARN_CONF_yarn_resourcemanager_recovery_enabled=trueYARN_CONF_yarn_resourcemanager_store_class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStoreYARN_CONF_yarn_resourcemanager_scheduler_class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerYARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___mb=8192YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___vcores=4YARN_CONF_yarn_resourcemanager_fs_state___store_uri=/rmstateYARN_CONF_yarn_resourcemanager_system___metrics___publisher_enabled=trueYARN_CONF_yarn_resourcemanager_hostname=resourcemanagerYARN_CONF_yarn_resourcemanager_address=resourcemanager:8032YARN_CONF_yarn_resourcemanager_scheduler_address=resourcemanager:8030YARN_CONF_yarn_resourcemanager_resource__tracker_address=resourcemanager:8031YARN_CONF_yarn_timeline___service_enabled=trueYARN_CONF_yarn_timeline___service_generic___application___history_enabled=trueYARN_CONF_yarn_timeline___service_hostname=historyserverYARN_CONF_mapreduce_map_output_compress=trueYARN_CONF_mapred_map_output_compress_codec=org.apache.hadoop.io.compress.SnappyCodecYARN_CONF_yarn_nodemanager_resource_memory___mb=16384YARN_CONF_yarn_nodemanager_resource_cpu___vcores=8YARN_CONF_yarn_nodemanager_disk___health___checker_max___disk___utilization___per___disk___percentage=98.5YARN_CONF_yarn_nodemanager_remote___app___log___dir=/app-logsYARN_CONF_yarn_nodemanager_aux___services=mapreduce_shuffleYARN_CONF_yarn_nodemanager_pmem___check___enabled=falseYARN_CONF_yarn_nodemanager_vmem___check___enabled=false#yarn.nodemanager.pmem-check-enabled：#是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默#认是true#yarn.nodemanager.vmem-check-enabled：#是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默#认是trueMAPRED_CONF_mapreduce_framework_name=yarnMAPRED_CONF_mapred_child_java_opts=-Xmx4096mMAPRED_CONF_mapreduce_map_memory_mb=4096MAPRED_CONF_mapreduce_reduce_memory_mb=8192MAPRED_CONF_mapreduce_map_java_opts=-Xmx3072mMAPRED_CONF_mapreduce_reduce_java_opts=-Xmx6144m hive-site.xml 123456789&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;thrift://hive-metastore:9083&lt;/value&gt; &lt;description&gt;Thrift URI for remote metastore.Used by metastore client to connect to remote metastore&lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; 说明 hadoop集群搭建版本兼容很重要，这里的hadoop、spark、hive的版本是一样的 hive-metastore作为元数据服务，对外共给客户端使用hiveserver、sparkclient、flinkclient等 postgresql是存储元数据的表、真正的数据在hdfs里面存着 hive-server是hive客户端，暴露10000端口，可以通过hivejdbc共给java调用，使用分区、简单查询等 1234docker-compose exec hive-server bash/opt/hive/bin/beeline -u jdbc:hive2://localhost:10000&gt; CREATE TABLE pokes (foo INT, bar STRING);&gt; LOAD DATA LOCAL INPATH '/opt/hive/examples/files/kv1.txt' OVERWRITE INTO TABLE pokes; 由于配置了yarn环境，hivesql会直接提交到yarn上面进行map-&gt;reduce操作,mr已经被弃用了，使用spark等进行内存运算会更快 resourcemanager、nodemanager是yarn的资源管理服务，实际任务是跑在nodemanager上面的，所以它于datanode放在一台机器最好，本地读取文件速度快 12$HADOOP_PREFIX/bin/hdfs --config $HADOOP_CONF_DIR datanode$HADOOP_PREFIX/bin/yarn --config $HADOOP_CONF_DIR nodemanager spark-master在这里只作为客户端，spark on yarn不需要启动spark集群，只需要配置yarn路径即可，然后任务提交到yarn，yarn会自己创建集群，分为客户端与集群两种方式提交 12/spark/bin/spark-submit --master yarn --deploy-mode cluster --class org.apache.spark.examples.SparkPi /spark/examples/jars/spark-examples_2.11-2.2.0.jar/spark/bin/spark-submit --master yarn --deploy-mode client --class org.apache.spark.examples.SparkPi /spark/examples/jars/spark-examples_2.11-2.2.0.jar 可以通过yarn命令查看日志等 12yarn application -list yarn logs -applicationId xxx"},{"title":"电影网站","date":"2021-01-10T04:31:54.000Z","path":"2021/01/10/电影网站/","text":"列表 牛牛TV：http://ziliao6.com/tv/ 片库网：https://www.pianku.tv/ 低端影视：http://ddrk.me 五号站：http://www.wuhaozhan.net 海免影院：http://www.haitudy.com 全视频TV：http://www.qsptv.com 独播库：https://www.duboku.net 哗嘀影视：https://www.bde4.com 星辰影院：http://www.vodxc.tv 豌豆影视：https://www.wandouys.com 酸枣电影网（66影视）：https://www.suanzao.tv 4K屋：http://www.kkkkmao.com 看看屋：https://www.kankanwu.com 蛋蛋赞影院：https://www.dandanzan.com 迅播影院：http://www.22tu.cc 酷绘视频：http://www.kuhuiv.com 去看TV：https://www.qukantv.net/ 我的电影网：http://www.wodedy.net 琪琪影院：https://www.77evd.cc/ 七七看片：https://www.77kpp.com/ 草民电影：https://www.cmdy5.com/ 私人官网：http://www.aishang118.cn/ 电影盒子：http://www.tv5box.com/ 全能影视：http://www.qnvod.net/ 影视分享：https://www.ysshare.com/ 94神马电影网：http://www.9rmb.com/ 好恐怖：http://www.hkb123.com/ 慢头影视：http://www.paojiaoys.com/ 影猫：http://www.mvcat.com/ BT猫：https://www.btmao.cc/ 神马电影网：https://www.jlszyy.cc/ 达达兔电影院：https://www.dadatutu.com/ 盐酥鸡：https://www.ysuzy.com/ 爱电影天堂：https://www.idytt.com/ 我乐电影：http://www.56dy.com/ 钉子电影：http://www.dingziyc.com/ 西瓜影院：https://www.xigua2222.com/ 片吧：http://www.pianba.tv/ 片库网：https://www.pianku.tv/ 无双影视：https://53ys.cc/ 80s手机电影网：http://www.8080s.net/ 西瓜电影：https://www.xigua110.com/ 人人影视：http://www.yyetss.com/ 高清资源网：http://www.gaoqingzy.com/ OK电影网：http://www.kk2w.cc/ 豆瓣电影资源采集网：http://www.douban666.com/ 87影院：https://www.87kk.tv/ 放映影院：https://www.t90dyy.tv/ 速影TV：https://suyingtv.com/ 嘀哆咪影视：https://www.haiduomi.cc/ 优片网：http://www.iupian.com/ 黑米影院：https://www.tv432.com/ 且听风吟：http://www.qtfy7.com/ 88影视网：https://www.88ys.com/ 嘀哩哩：http://www.dililitv.com/ 云播TV：https://www.yunbtv.com/ 田鸡影院：http://www.tianjiyy123.com/ 奈非影视：https://www.nfmovies.com/ 全集网：https://www.quanji789.com/ 全集网：http://quanji456.com/ 狗带TV：http://www.goudaitv1.com/ 五杀电影院：https://www.lol5s.com/ 蓝马影视：https://www.lanmays.com/ 奇葩影视：https://www.qpvod.com/ 迅雷哥：https://www.4142.cc/ 影视分享：https://www.ysshare.com/ 新视觉影院：http://www.yy6080.cn/ v部落：http://www.vbuluo99.com/ 神驴影院：http://www.shenlvyy.com/ 美鱼剧场：http://www.hailiys.com/ 吼：http://hoho.tv/ 酷云影视：https://kuyun.tv/ 想看剧：https://www.xiangkanju.cc/ 去看TV：http://www.qukantv.net/ 胖子视频：http://www.pangzi.ca/ 海外影院：https://www.haiwaiyy.com/ 好吧：http://hao8tv.com/ 日本影视：http://www.jp2468.com/ TNT影视：http://www.tntdy2.vip/ 优乐电影网：http://www.youlebe.com/ 面包网：https://www.mianbao99.com/ 猫哈哈：http://www.maohaha.com/ 七七电视：https://www.77ds.vip/ 欧西电影：https://www.ouxi.me/ 青鸟影视：https://www.qingniao.me/ 蓝鲸电影：https://www.ljmovie.com/ 葡萄影视：https://www.putaoys.com/ 太初电影：https://www.tcmove.com/ 爱美剧：https://www.meiju.net/ 天天看美剧：http://www.ttkmj.tv/ 日剧TV：https://www.rijutv.com/ 完美看看：https://www.wanmeikk.me/ 吾爱看影视：http://www.5aikp.com/ 播王：https://bowan.su/ Gimy TV剧迷：https://gimy.tv/ NO视频：http://www.novipnoad.com/ 枫林网：http://8maple.ru/ 91美剧：https://91mjw.com/ 美剧鸟：http://www.meijuniao.com/ 韩剧集网：https://www.juji.tv/ BT电影天堂：http://www.btbtdy.me 在线之家：https://www.zxzjs.com 139影视：https://www.139ys.com/ 两个BT：http://www.bttwo.com 电影蜜蜂：https://www.dybee.tv 新版6v影院：https://www.66s.cc 韩剧网：http://www.hanju.cc/ 韩剧TV：https://www.hanjutv.com/ Zzzfun：http://www.zzzfun.com/ 妮可动漫：http://www.nicotv.me/ 吐槽弹幕网：http://www.tucao.one/ 动漫岛：http://www.dmd8.com/ 碟影视界：http://www.952780.com/ 皮皮影视网：https://www.taiks.com/ ADC电影网：https://www.adcmove.com/"},{"title":"Docker使用","date":"2020-12-20T04:01:09.857Z","path":"2020/12/20/Docker使用/","text":"阿里源安装docker yum安装123yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum makecache fastyum -y install docker-ce 二进制安装 安装 1234567891011121314151617181920tar -xvf docker-17.03.0-ce.tgzcp docker/* /usr/local/binvim /etc/systemd/system/docker.service[Unit]Description=Docker Application Container EngineDocumentation=http://docs.docker.io[Service]ExecStart=/usr/local/bin/dockerdExecReload=/bin/kill -s HUP $MAINPIDRestart=alwaysRestartSec=5LimitNOFILE=infinityLimitNPROC=infinityLimitCORE=infinityDelegate=yesKillMode=process[Install]WantedBy=multi-user.target 执行命令 1234systemctl daemon-reload //重载systemd下 xxx.service文件systemctl status dockersystemctl start docker //启动Dockersystemctl enable docker.service //设置开机自启 docker 安装目录修改 软连接方式 123456systemctl start dockersystemctl stop dockercd /var/libcp –rf docker /datarm –rf dockerln –s /data/docker docker 镜像导入导出 12docker save nginx &gt; nginx.tardocker load &lt; nginx.tar 默认配置文件 usr/lib/systemd/system/docker.service 如果更改存储目录就添加 – graph=/opt/docker 如果更改 DNS 默认采用宿主机的 dns – dns=xxxx 的方式指定 dockerfile 文件 Python版本 123456FROM python:3.6WORKDIR /usr/src/modelclassifyADD . .RUN pip install --no-cache-dir -i https://mirrors.aliyun.com/pypi/simple/ -r requirements.txtEXPOSE 5000CMD uwsgi Named_entity_recognition_uwsgi.ini Java版本 12345FROM java:8WORKDIR /usr/src/wordCountADD . .EXPOSE 8080CMD java -jar app.jar docker build 后面的 . 是重点 1docker build -t jc/ner:v1.0 . docker run 1docker run -d(后台启动) -p 5000(外部访问):80(内部暴露) jc/ner:版本号 docker-compose 单机容器编排 安装 123sudo curl -L \"https://github.com/docker/compose/releases/download/1.24.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-composedocker-compose --version 新建docker-compose.yml文件及配置 12345678version: \"3\"services: ner: image: \"jc/ner:v1.1\" #镜像 ports: #端口 - \"5001:5001\" region: ..... 命令 123docker-compose up (-d)docker-compose downdocker-compose ps docker 常用命令 镜像类 12345678docker build --rm=true . 构建镜像docker pull $&#123;IMAGE&#125; 安装镜像docker images 显示已经安装的镜像docker images --no-trunc 显示已经安装镜像的详细内容docker rmi $&#123;IMAGE_ID&#125; 删除指定镜像docker rmi -f $(docker images | grep none | awk '&#123;print $3&#125;' | xargs)docker rmi -f $(docker images | awk \"/^&lt;none&gt;/ &#123; print $3 &#125;\") 删除所有是none的dockers镜像docker rmi $(docker images --quiet --filter &amp;quot;dangling=true&amp;quot;) 删除未使用的镜像 容器类 123456789101112docker run 运行容器docker ps 显示正在运行的容器docker ps -a 显示所有的容器docker stop $&#123;CID&#125; 停止指定容器docker ps -a --filter &amp;quot;exited=1&amp;quot; 显示所有退出状态为1的容器docker rm $&#123;CID&#125; 删除指定容器docker ps -a | grep wildfly | awk '&#123;print $1&#125;' | xargs docker rm -f 使用正则表达式删除容器docker stop docker ps -q 停止所有正在运行的容器docker rm $(docker ps -aq) 删除所有停止的容器docker rm -f $(docker ps -a | grep Exit | awk '&#123; print $1 &#125;') 删除所有退出的容器docker exec -it $&#123;CID&#125; /bin/sh 进入容器打开一个shelldocker ps | grep wildfly | awk \"&#123;print $1&#125;\" 通过正则表达式查找容器的镜像ID"},{"title":"一些工具总结","date":"2020-11-29T11:27:48.000Z","path":"2020/11/29/一些工具总结/","text":"批量打包镜像1docker save $(docker images | grep -v REPOSITORY | awk 'BEGIN&#123;OFS=\":\";ORS=\" \"&#125;&#123;print $1,$2&#125;') -o package.tar 一些命令123456789101112java -jar xxx.jar -d -m test@test.com -n wiki -p conf -o http://localhost:8090 -s 编码java -jar xxx.jar -d -m test@test.com -n jira -p jira -o http://localhost:8080 -s 编码java -jar xxx.jar -d -m test@test.com -n jira -p 'is.origo.jira.tempo-plugin' -o qipukeji -s 编码SHOW VARIABLES LIKE 'tx%';SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;jdbc:mysql://mysql:3306/wiki?sessionVariables=tx_isolation='READ-COMMITTED'set global max_allowed_packet = 2*1024*1024*10show VARIABLES like '%max_allowed_packet%'; 给普通用户添加sudo权限12345chmod u+w /etc/sudoersvim /etc/sudoers在root下面添加qpkj ALL=(ALL) ALLchmod u-w /etc/sudoers 自定义yum源1234567/etc/yum.repos.d下面新建local.repo[lv]name=lvbaseurl=file:///root/lvenabled=1gpgcheck=0lv里面就是各种rpm包，然后就可以使用yuminstall安装了 硬盘操作12345678910111213141516查看服务器安装的硬盘状态（包括格式化和未格式化）fdisk –l添加新分区fdisk /dev/vdbN 回车P 回车1 回车两次回车W 回车fdisk –l格式化分区mkfs -t ext4 /dev/vdb1挂载硬盘mount /dev/vdb1 /data让系统开机自动挂载这块硬盘echo \"/dev/vdb1 /data ext4 defaults 0 0\"&gt;&gt;/etc/fstab helm安装123github下载二进制包tar -zxvf helm-v3.3.0-rc.2-linux-amd64.tar.gzsudo mv linux-amd64/helm /usr/bin/helm harbor安装123tar -zxvf harbor-offline-installer-v2.0.2.tgz拷贝一份harbor.yml，修改hostname，端口号，挂载卷等执行命令./install.sh (--with-chartmuseum) 用http登录harbor12vim /etc/docker/daemon.json\"insecure-registries\":[\"xulovemin1413.xyz:8080\"] 安装push插件12345helm plugin install https://github.com/chartmuseum/helm-push.git添加源helm repo add harbor http://xulovemin1413.xyz:8080/chartrepo/lixu --username admin --password Harbor12345helm push helm install pip离线安装123pip freeze &gt;requirements.txtpip download -d c:\\tempfile -r &gt;requirements.txtpip install --no-index --find-links=c:\\tempfile -r requirements.txt anaconda一些命令1234567891011121314151617conda config --set auto_activate_base false 不自动激活进入base环境conda env listconda listconda installconda activate 虚拟环境conda deactivateconda create -n 环境名 python=3.6conda remove -n 环境名 --allconda --version # 查看当前conda版本conda update conda # 升级当前condaconda config --show-sources#添加清华的源conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda环境导出conda env export --file abc.ymlconda env create -f abc.yml WIN10升级企业版密钥NPPR9-FWDCX-D2C8J-H872K-2YT43"},{"title":"K8s的总结","date":"2020-11-29T11:17:34.000Z","path":"2020/11/29/K8s的总结/","text":"k8s安装 设置yum源 12345678vi /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg 临时关闭swap 12swapoff -aswapon -a 安装工具 12yum install -y kubelet kubeadm kubectlsystemctl start kubelet 启动k8s集群 1kubeadm init --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.16.0 （--ignore-preflight-errors=all一核报错） 修改端口号 123vim /etc/kubernetes/manifests/kube-apiserver.yaml设置insecure-port=8080重启 docker restart kube-apiserver_kube-apiserver这个容器 安装网络插件 123kubectl apply -f https://docs.projectcalico.org/v3.14/manifests/calico.yaml或者wget https://raw.githubusercontent.com/coreos/flannel/v0.12.0/Documentation/kube-flannel.yml 从节点部署 123安装kubeadm、kubeletsystemctl start kubelet然后加入集群kubeadm token create --print-join-command查看加入集群命令 rancher导入k8s 1wget --no-check-certificate https://10.0.1.186/v3/import/8xhq4r95ptgghqbwx2sgf8t8vlvt5sg6wcqmvspwmn72dh4r7mp9lg.yaml 一些常用命令 1234567891011121314kubectl get servicekubectl get deploykubectl get pods --all-namespaceskubectl get pods --all-namespaces -o widekubectl get deployments --all-namespaceskubectl delete deployments kubernetes-dashboard -n kube-systemkubectl describe pod -n kube-system kubectl describe pod name -o yaml允许master节点部署pod，使用命令如下:kubectl taint nodes --all node-role.kubernetes.io/master-禁止master部署podkubectl taint nodes dvbd06 node-role.kubernetes.io/master=true:NoSchedule列出所有的kindkubectl api-resources -o wide --namespaced=true k8s彻底清除脚本 123456789101112131415161718192021docker rm -f $(sudo docker ps -aq);docker volume rm $(sudo docker volume ls -q);rm -rf /etc/cni \\ /etc/kubernetes \\ /opt/cni \\ /opt/rke \\ /run/secrets/kubernetes.io \\ /run/calico \\ /run/flannel \\ /var/lib/calico \\ /var/lib/etcd \\ /var/lib/cni \\ /var/lib/kubelet \\ /var/lib/rancher/rke/log \\ /var/log/containers \\ /var/log/pods \\ /var/run/calicofor mount in $(mount | grep tmpfs | grep '/var/lib/kubelet' | awk '&#123; print $3 &#125;') /var/lib/kubelet /var/lib/rancher; do umount $mount; donerm -f /var/lib/containerd/io.containerd.metadata.v1.bolt/meta.dbsudo systemctl restart containerdsudo systemctl restart docker"},{"title":"Jenkins使用","date":"2020-11-29T05:33:23.000Z","path":"2020/11/29/Jenkins使用/","text":"Jenkins安装 启动Jenkins123456789101112131415version: '3'services: jenkins: container_name: jenkins image: jenkinsci/blueocean # 指定docker用户 user: root ports: - 8090:8080 volumes: - /data/jenkins:/var/jenkins_home # 这个很重要，可以让Jenkins容器里面使用docker - /var/run/docker.sock:/var/run/docker.sock # 以让Jenkins容器里面使用docker-compose - /usr/local/bin/docker-compose:/usr/local/bin/docker-compose jenkins系统管理配置 webhook配置（github或者gitlab） sshserver配置(需要下载插件Publish Over SSH) jenkins全局工具配置 jdk与git（系统默认就带、使用默认配置即可） docker与maven（确定之后不会立即下载，会在jenkins流程需要的时候下载） docker需要下载（CloudBees Docker Build and Publish plugin）这个插件 maven需要下载（Maven Integration plugin）这个插件 jenkins全局凭据管理 保存git、harbor等用户名密码 新建jenkins任务 老版本构建、通过界面配置方式 新建项目（构建一个maven项目） 源码管理（配置git或者gitlab） 构建触发器（使用git或者gitlab的webhook自动触发） maven编译以及push到harbor ssh远程主机运行docker容器 以piplines的方式构建任务 主要是以groovy代码的方式构建 可以有逻辑判断等 能调用Blue Ocean查看完整构建状态 可以用git存储流程代码，方便 前面配置一样，流程在下面的代码里面 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051pipeline &#123; # 指定机器运行，可选any、label、docker等 agent &#123; label 'master' &#125; stages &#123; # 拉取git代码，根据分支不同建立不同的任务，到时候各自分支提交会自动出发相应的构建流程 stage('Git Pullling') &#123; steps &#123; git branch: 'develop', credentialsId: 'xulovemin', url: 'https://github.com/xulovemin/demo.git' &#125; &#125; stage('Maven Build') &#123; # 使用系统设置中安装的工具 tools &#123; maven 'maven' &#125; steps &#123; sh 'mvn clean package -Dmaven.test.skip' &#125; &#125; stage('Docker Build') &#123; # 系统运行起来自动带docker环境 steps &#123; sh 'docker build -t localhost:8070/library/demo .' sh 'docker push localhost:8070/library/demo' &#125; &#125; stage('Deployment') &#123; # 远程ssh服务器，需要下载SSH Pipeline Steps这个插件 # 不同的构建环境ssh不同的主机 steps &#123; script &#123; def remote = [:] remote.name = 'server' remote.host = 'xulovemin1413.xyz' remote.user = 'root' remote.password = 'Lixu1989' remote.port = 22 remote.allowAnyHosts = true sshCommand remote: remote, command: \"\"\" docker pull xulovemin1413.xyz:8070/library/demo cd /work/demo docker-compose down docker-compose up -d \"\"\" &#125; &#125; &#125; &#125;&#125; 自动部署Vue流程 12345678910111213141516171819202122232425262728293031323334353637pipeline &#123; agent &#123; label 'master' &#125; stages &#123; stage('Git Pullling') &#123; steps &#123; git branch: 'master', credentialsId: 'xulovemin', url: 'https://github.com/xulovemin/demovue.git' &#125; &#125; stage('Node Build') &#123; tools &#123; nodejs 'node' &#125; steps &#123; sh 'npm install' sh 'rm -rf ./dist/*' sh 'npm run build' &#125; &#125; stage('Deployment') &#123; steps &#123; script &#123; def remote = [:] remote.name = 'server' remote.host = 'xulovemin1413.xyz' remote.user = 'root' remote.password = 'Lixu1989' remote.port = 22 remote.allowAnyHosts = true sshCommand remote: remote, command: 'rm -rf /work/nginx/dist/*' sshPut remote: remote, from: 'dist', into: '/work/nginx' &#125; &#125; &#125; &#125;&#125; 查看Blue Ocean流程图 用户权限配置（安装Role-based Authorization Strategy）这个插件"},{"title":"Python实用工具","date":"2019-12-26T00:38:50.000Z","path":"2019/12/26/Python实用工具/","text":"工具汇总 扫描第三方包 12pip install pipreqspipreqs ./ --encoding=utf8 查询安装模块 123pip freeze &gt;requirements.txt # 查询安装模块pip download -d D:\\pypackage -r requirements.txt # 推荐使用pip install --no-index --find-links=D:\\pypackage -r requirements.txt # 拷贝过来的文件 共享电脑文件 1python -m http.server 8888 网站视频下载神器 下载依赖包 1pip install you-get 查看视频的详细信息 1you-get -i url 参数详解 123-o 文件绝对路径-O 文件重命名--format=flv 需要下载的版本号 获取RUL的json信息 1you-get --json url py注册到nacos给springcloud调用 123456789101112131415161718192021222324252627282930313233from flask import Flaskimport nacosfrom apscheduler.schedulers.background import BackgroundSchedulerfrom flask_restful import Resource, fields, marshal_with, Apiapp = Flask(__name__)api = Api(app)# 后台定时任务scheduler = BackgroundScheduler()SERVER_ADDRESSES = \"localhost:8848\"na_client = nacos.NacosClient(SERVER_ADDRESSES)#注册到nacosna_client.add_naming_instance('py', 'localhost', 5000)@scheduler.scheduled_job('cron', second='*/5')def send_heartbeat(): na_client.send_heartbeat('py', 'localhost', 5000)#定时5秒向nacos发送心跳scheduler.start()class Index(Resource): @marshal_with(i_filed) def get(self): return &#123;'data': ''&#125;api.add_resource(Index, '/')app.run() springcloud项目配置fegin调用 12345678910111213package com.example.service;import com.example.vo.Result;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;@FeignClient(value = \"py\", fallback = PyInterFaceImpl.class)public interface PyInterFace &#123; @GetMapping(\"/\") Result top();&#125;"},{"title":"Elasticsearch集群","date":"2019-11-26T10:12:37.000Z","path":"2019/11/26/Elasticsearch集群/","text":"直接贴compose文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758version: &apos;3&apos;services: elasticsearch_n0: image: elasticsearch:6.8.4 container_name: elasticsearch_n0 environment: - cluster.name=elasticsearch-cluster - node.name=node0 - node.master=true - node.data=true - bootstrap.memory_lock=true - http.cors.enabled=true - http.cors.allow-origin=* - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; - &quot;discovery.zen.ping.unicast.hosts=elasticsearch_n0,elasticsearch_n1,elasticsearch_n2&quot; - &quot;discovery.zen.minimum_master_nodes=2&quot; ulimits: memlock: soft: -1 hard: -1 ports: - 9200:9200 elasticsearch_n1: image: elasticsearch:6.8.4 container_name: elasticsearch_n1 environment: - cluster.name=elasticsearch-cluster - node.name=node1 - node.master=true - node.data=true - bootstrap.memory_lock=true - http.cors.enabled=true - http.cors.allow-origin=* - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; - &quot;discovery.zen.ping.unicast.hosts=elasticsearch_n0,elasticsearch_n1,elasticsearch_n2&quot; - &quot;discovery.zen.minimum_master_nodes=2&quot; ulimits: memlock: soft: -1 hard: -1 elasticsearch_n2: image: elasticsearch:6.8.4 container_name: elasticsearch_n2 environment: - cluster.name=elasticsearch-cluster - node.name=node2 - node.master=true - node.data=true - bootstrap.memory_lock=true - http.cors.enabled=true - http.cors.allow-origin=* - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; - &quot;discovery.zen.ping.unicast.hosts=elasticsearch_n0,elasticsearch_n1,elasticsearch_n2&quot; - &quot;discovery.zen.minimum_master_nodes=2&quot; ulimits: memlock: soft: -1 hard: -1 Linux部署注意，需要修改内存 123vi /etc/sysctl.conf最后加上vm.max_map_count=262144sysctl -p kafka环境搭建 12345678910111213141516171819version: &apos;3&apos;services: zookeeper: image: wurstmeister/zookeeper ports: - 2181:2181 kafka: image: wurstmeister/kafka ports: - 9092:9092 environment: KAFKA_ADVERTISED_HOST_NAME: 172.17.5.96 KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 manager: image: sheepkiller/kafka-manager ports: - 9001:9000 environment: ZK_HOSTS: zookeeper:2181 zookeeper集群 1234567891011121314151617181920212223242526272829version: &apos;3&apos;services: zoo1: image: zookeeper:3.4.11 hostname: zoo1 container_name: zookeeper_1 ports: - 2181:2181 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo2: image: zookeeper:3.4.11 hostname: zoo2 container_name: zookeeper_2 ports: - 2182:2181 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo3: image: zookeeper:3.4.11 hostname: zoo3 container_name: zookeeper_3 ports: - 2183:2181 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 flink集群环境 12345678910111213141516version: &quot;3&quot;services: jobmanager: image: flink ports: - 8081:8081 command: jobmanager environment: - JOB_MANAGER_RPC_ADDRESS=jobmanager taskmanager: image: flink depends_on: - jobmanager command: taskmanager environment: - JOB_MANAGER_RPC_ADDRESS=jobmanager"},{"title":"rancher搭建","date":"2019-10-25T01:06:23.000Z","path":"2019/10/25/rancher搭建/","text":"环境准备 多台机器 安装Rancher Rancer2.X在一台机器上执行1sudo docker run -d --restart=unless-stopped -v &lt;主机路径&gt;:/var/lib/rancher/ -p 80:80 -p 443:443 rancher/rancher 登陆Rancker 新建集群 在另一台或者几台机器上执行提示命令即可 等待集群搭建成功 一些Rancher操作 工作负载部署服务的地方，可以建立多个命名空间，作用是用于隔离网络的 负载均衡将服务映射到域名的功能 服务发现不用命名空间可以相互调用服务 PVC卷目录映射配置 NFS映射主机目录 添加应用商店 商店名称 url mirror-stable http://mirror.azure.cn/kubernetes/charts/ 启动应用商店nfs-server需要启动找到nfs-client-provisioner启动，配置nfs.path对应目录地址 例如：/data/work/share nfs.server 对应nfs服务器 例如：192.168.1.130 然后就可以在pvc里面新建存储类PV了"},{"title":"DockerSwarm","date":"2019-10-11T12:51:21.000Z","path":"2019/10/11/DockerSwarm/","text":"Swarm常用命令 docker service -h swarm stack 启动脚本 12345#!/bin/shservice_name='redis'echo \"start service...\"docker stack deploy -c docker-compose.yaml $service_nameecho \"done!!!\" NFS挂载共享目录 查看是否安装 1rpm -qa nfs-utils rpcbind 安装 1sudo yum install -y nfs-utils rpcbind 编辑共享目录 1234vi /etc/exports/data/work/share 172.16.11.0/24(rw,sync,no_root_squash)orecho \"/nfs4k8s *(rw,async,no_root_squash)\" &gt;&gt; /etc/exports 配置生效 1exportfs -rv 启动服务 1234sudo systemctl enable rpcbindsudo systemctl start rpcbindsudo systemctl enable nfs-serversudo systemctl start nfs-server compose文件配置 1234567891011121314version: \"3\"services: nginx: image: nginx:alpine ports: - 80:80 volumes: - myvolume:/usr/share/nginx/htmlvolumes: myvolume: driver_opts: type: \"nfs\" o: \"addr=172.16.11.130,rw\" device: \":/data/work/share\""},{"title":"模糊金库","date":"2019-08-29T03:09:55.000Z","path":"2019/08/29/模糊金库/","text":"模糊金库上锁 密钥 K，计算 CRC 校验码，构成多项式 f(x) 多项式由密钥k、循环校验码组成 将集合 A 投影到 f(x) 上形成 (a, f(a)) 得到真实节点集合 A可以是指纹、静脉、虹膜等 随机添加大量噪声，合并真实节点与噪声集合，并乱序 1.噪声节点数量远远多于真实节点 2.噪声节点不能落在f(x)上 得到基于生物特征的模糊金库 V 解锁 采集用户特征形成集合 B B与A属于一类特征 将 B 与模糊金库 V 对比 假设阈值m，如果匹配大于等于m则进入候选集 H，否则失败 从候选集 H 中取出m个点，利用拉格朗日插值法重构出多项式 再利用 CRC 校验码校验多项式系数，验证是否正确 如果 CRC 校验符合，则恢复密钥K成功 否则，重新从候选集 H 中再取出m个点来重构多项式 直到进行了最后操作仍未恢复密钥 K，失败 改进 多生物特征的模糊金库算法 细节点形变的模糊金库算法 一些提示资料 生物特征识别技术主要包括指纹识别、指静脉识别、虹膜识别、掌纹识别、人脸识别、声音识别、DNA等识别等技术 生物识别技术已经取代传统的密码或ID 卡，成为一项方便可靠的验证人身份的技术 生物特征的身份认证需要存储注册用户的生物特征模板 一个人的生物特征有限，如果被他人别有用心地窃取到，那么生物特征模板也就会被窃取到，这将会带来严重的后果 加密过程是不可逆的，即原本的生物特征不能直接从加密模板中得到 相比于指纹、手形、掌纹等手部特征，采用手指静脉特征进行加密具有独特的优越性 处理指静脉的特征模板，将模板以点对的形式混杂在大量的干扰数据中。攻击者很难从混杂的大量数据中提取出真实的指静脉特征，这样便起到了加密的作用。只有拥有真实样本的解密者才能成功解密，得到密钥 采用带有循环冗余检验码的指静脉密钥绑定算法。这种算法能够降低错误匹配指静脉的概率，同时能提高加密的准确性，降低加密信息被攻击者破解的概率。 对适用于指静脉的模糊金库算法，采用细节点生成方法得到指静脉细节点，再添加大量的杂凑点对真实点进行隐藏，对真实点利用密钥绑定多项式，而对杂凑点则利用随机数计算。在恢复密钥时，通过比对查询指静脉中的细节点和模糊金库中的点的坐标信息，选择相匹配的细节点并进行相反计算，求得多项式并恢复出保护的密钥。 模糊金库算法的目的在于利用一种具有模糊性的信息对某个密钥进行保护。随着生物特征识别的兴起，研究者们发现生物特征具有很好的模糊性，且利用生物特征生成模糊金库的算法具有良好的性能。由于指纹识别技术起步较早且发展较为成熟，针对基于生物特征的模糊金库研究大多基于指纹特征，随着研究的发展也相继出现了基于人脸、虹膜的模糊金库方案，而基于指静脉的模糊金库方案的研究则较为匮乏。其中已有的指纹模糊金库算法也存在一些缺陷，解锁时查询手指一旦发生改变，有可能无法正确解锁出所保存的密钥信息。为了解决这一问题，有研究者提出使用一小部分辅助数据来实现指纹对准技术，从而增强模糊金库的实用性，但辅助数据也将泄露一部分信息，因此不利于模糊金库的安全性。本章节遵循这一思路，提出一种较安全且便捷的基于手指静脉的模糊金库算法。 CRC 码（Cyclic Redundancy Check），全称叫做循环冗余检验码。其基本思路为：在发送端，根据长度为k位的二进制信息码，通过一定的规则来产生一个长度为r位的冗余监督码，该监督码的作用是在于校验信息，附在k位的信息序列后，形成一个新的n=k+r 位的二进制序列，也称为(n, k)码。在接收端，根据 CRC 码的规则进行校验，从而来确定在传输过程中数据是否发生错误。 测试 训练数据规模 测试集规模 模型 训练时长 训练集准确率 测试集准确率 4W 1W CNN 15*20s 0.984 0.959 4W 1W LSTM 51*20s 0.838 0.717"},{"title":"nginx部署与负载","date":"2019-07-09T05:52:39.000Z","path":"2019/07/09/nginx部署与负载/","text":"nginx容器内的一些目录 /usr/share/nginx 存放静态html /var/log/nginx 存放log的地方 /etc/nginx 存放nginx.conf配置的地方，它引入的是下面路径里面的conf文件 /etc/nginx/conf.d 引入的conf文件，默认default.conf，可以自定义 运行nginx时需要将default.conf拷贝出来，然后挂载到容器里面 1docker cp containerid:/etc/nginx/conf.d/default.conf 宿主机目录 运行nginx容器 将内置文件挂载 1docker run -d -p 80:80 -v 宿主机目录:/etc/nginx/conf.d nginx 然后就可以修改conf或者新增conf让nginx读取配置 使用配置 docker启动一个web项目，不用映射外网端口，保证服务安全 配置nginx的conf文件 1234567server &#123; listen 80; location / &#123; # 内网ip端口即可访问 proxy_pass http://172.17.0.2:5000; &#125;&#125; nginx配置stream,新版本功能，可以代理TCP协议，可以负载MySQL、oracle等 123456789stream&#123; upstream mysql&#123; server mysql:3306; &#125; server&#123; listen 3306; proxy_pass mysql; &#125;&#125; nginx支持高并发，放到服务前面缓解压力 nginx简单的负载均衡 在刚才的服务基础上在启动一个服务 配置conf文件 123456789101112upstream lixu_proxy &#123; server 172.17.0.2:5000 weight=1; server 172.17.0.4:5000 weight=2;&#125;server &#123; listen 80; access_log /var/log/nginx/nginx_access.log; error_log /var/log/nginx/nginx_error.log; location / &#123; proxy_pass http://lixu_proxy; &#125;&#125; 设备状态 down：表示单前的server暂时不参与负载 weight：权重，默认为1，weight越大，负载的权重就越大 max_fails：允许请求失败的次数默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误 fail_timeout：max_fails次失败后，暂停的时间 backup：备用服务器, 其它所有的非backup机器down或者忙的时候，请求backup机器，所以这台机器压力会最轻"},{"title":"mongo集群分片","date":"2019-07-04T05:39:09.000Z","path":"2019/07/04/mongo集群分片/","text":"介绍 主要分为三部分，配置服务副本集、分片副本集、连接 mongos 到分片集群，增加分片到集群 编写dockerFile –configsvr的作用是将端口改为27019 –shardsvr的作用是将端口改为27018 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162version: '3'services: conf1: image: mongo:3.4 container_name: conf1 ports: - 27017:27019 command: mongod --configsvr --dbpath /data/db --replSet conf conf2: image: mongo:3.4 container_name: conf2 ports: - 27018:27019 command: mongod --configsvr --dbpath /data/db --replSet conf conf3: image: mongo:3.4 container_name: conf3 ports: - 27019:27019 command: mongod --configsvr --dbpath /data/db --replSet conf sh1: image: mongo:3.4 container_name: sh1 ports: - 27027:27018 command: mongod --shardsvr --dbpath /data/db --replSet sh1 sh2: image: mongo:3.4 container_name: sh2 ports: - 27028:27018 command: mongod --shardsvr --dbpath /data/db --replSet sh1 sh3: image: mongo:3.4 container_name: sh3 ports: - 27029:27018 command: mongod --shardsvr --dbpath /data/db --replSet sh1 sh4: image: mongo:3.4 container_name: sh4 ports: - 27037:27018 command: mongod --shardsvr --dbpath /data/db --replSet sh2 sh5: image: mongo:3.4 container_name: sh5 ports: - 27038:27018 command: mongod --shardsvr --dbpath /data/db --replSet sh2 sh6: image: mongo:3.4 container_name: sh6 ports: - 27039:27018 command: mongod --shardsvr --dbpath /data/db --replSet sh2 mongos: image: mongo:3.4 container_name: mongos ports: - 21017:27017 command: mongos --configdb conf/172.16.11.130:27017,172.16.11.130:27018,172.16.11.130:27019 启动docker容器 配置服务副本集12345678910111213141516171819docker-compose exec conf1 mongo --port=27019config = &#123; \"_id\" : \"conf\", \"members\" : [ &#123; \"_id\" : 0, \"host\" : \"172.16.11.130:27017\" &#125;, &#123; \"_id\" : 1, \"host\" : \"172.16.11.130:27018\" &#125;, &#123; \"_id\" : 2, \"host\" : \"172.16.11.130:27019\" &#125; ]&#125;rs.initiate(config) 配置分片1、2副本集1234567891011121314151617181920212223242526272829303132333435363738docker-compose exec sh1 mongo --port=27018config = &#123; \"_id\" : \"sh1\", \"members\" : [ &#123; \"_id\" : 0, \"host\" : \"172.16.11.130:27027\" &#125;, &#123; \"_id\" : 1, \"host\" : \"172.16.11.130:27028\" &#125;, &#123; \"_id\" : 2, \"host\" : \"172.16.11.130:27029\" &#125; ]&#125;rs.initiate(config)docker-compose exec sh4 mongo --port=27018config = &#123; \"_id\" : \"sh2\", \"members\" : [ &#123; \"_id\" : 0, \"host\" : \"172.16.11.130:27037\" &#125;, &#123; \"_id\" : 1, \"host\" : \"172.16.11.130:27038\" &#125;, &#123; \"_id\" : 2, \"host\" : \"172.16.11.130:27039\" &#125; ]&#125;rs.initiate(config) 配置mongos添加分片123docker-compose exec mongos mongosh.addShard(\"sh1/172.16.11.130:27027,172.16.11.130:27028,172.16.11.130:27029\")sh.addShard(\"sh2/172.16.11.130:27037,172.16.11.130:27038,172.16.11.130:27039\") 数据库、集合启用分片12sh.enableSharding(\"test\")sh.shardCollection(\"test.test\", &#123;\"_id\": \"hashed\" &#125;) python连接mongos测试1234567import pymongomyclient = pymongo.MongoClient(\"mongodb://172.16.11.130:21017\")mydb = myclient['test']mycol = mydb['test']for i in range(1000): mycol.insert_one(&#123;'name': \"李旭\", 'sex': '男'&#125;) 验证故障转移12docker stop sh1docker stop sh4 将两台主机关机，然后查询"},{"title":"docker哨兵","date":"2019-06-27T08:42:13.000Z","path":"2019/06/27/docker哨兵/","text":"主从复制 开启3个Redis服务 123docker run --name redis-6379 -p 6379:6379 -d redisdocker run --name redis-6380 -p 6380:6379 -d redisdocker run --name redis-6381 -p 6381:6379 -d redis 分别查看主机ip 1docker inspect containerid 进入docker容器内部，分配主从 12docker exec -it containerid redis-clislaveof 主ip 6379 查看主从角色 1info replication Sentinel哨兵 新建sentinel.conf文件 123456port 26379sentinel deny-scripts-reconfig yes# Redis监控mymaster，投票达到1则表示master挂掉了sentinel monitor mymaster 172.17.0.4 6379 1# 10秒内mymaster还没活过来，则认为master宕机了sentinel failover-timeout mymaster 10000 启动哨兵服务 1docker run --name redis-26379 -p 26379:26379 -v /data/work/redistest/sentinel.conf:/usr/local/etc/redis/sentinel.conf -d redis redis-sentinel /usr/local/etc/redis/sentinel.conf 查看哨兵节点日志 进入哨兵节点，查看是否有主节点 123docker exec -it containerid bashredis-cli -p 26379sentinel master mymaster 哨兵节点也可以集群，这里只搭建一个哨兵节点 docker暂停主节点，过一会自动将从节点变为主节点 python访问哨兵集群12345678910111213from redis.sentinel import Sentinelsentinel = Sentinel([('172.16.11.130', 26379)])master = sentinel.discover_master('mymaster')print(master)slave = sentinel.discover_slaves('mymaster')print(slave)master = sentinel.master_for('mymaster')master.set('foo', 'bar')slave = sentinel.slave_for('mymaster')r_ret = slave.get('foo')print(r_ret)"},{"title":"mongo集群","date":"2019-06-21T07:07:37.000Z","path":"2019/06/21/mongo集群/","text":"一主两从 可进行读写分离 具备故障转移能力 1234567891011121314151617version: '3'services: rs1: image: mongo:3.4 ports: - 27017:27017 command: mongod --dbpath /data/db --replSet myset rs2: image: mongo:3.4 ports: - 27018:27017 command: mongod --dbpath /data/db --replSet myset rs3: image: mongo:3.4 ports: - 27019:27017 command: mongod --dbpath /data/db --replSet myset 运行完docker-compose up之后执行一下操作初始化12345678910111213141516171819docker-compose exec rs1 mongoconfig = &#123; \"_id\" : \"myset\", \"members\" : [ &#123; \"_id\" : 0, \"host\" : \"172.16.11.130:27017\" &#125;, &#123; \"_id\" : 1, \"host\" : \"172.16.11.130:27018\" &#125;, &#123; \"_id\" : 2, \"host\" : \"172.16.11.130:27019\" &#125; ]&#125;rs.initiate(config) 查看配置与副本级状态 12rs.conf() rs.status() 插入信息到主节点 123docker-compose exec rs1 mongouse testdb.test.insert(&#123;msg: 'this is from primary', ts: new Date()&#125;) 在副本集中检测信息是否同步 12345678docker-compose exec rs2 mongors.slaveOk()use testdb.test.find()docker-compose exec rs3 mongors.slaveOk()use testdb.test.find() 故障测试 123docker-compose stop rs1docker-compose exec rs2 mongodocker-compose exec rs3 mongo 使用副本集群 12345import pymongomyclient = pymongo.MongoClient(\"mongodb://172.16.11.130:27017,172.16.11.130:27018,172.16.11.130:27019\")mydb = myclient['test']mycol = mydb['test']mycol.insert_one(&#123;'name': '李旭', 'sex': '男'&#125;)"},{"title":"Linux常用","date":"2019-06-12T07:09:29.000Z","path":"2019/06/12/Linux常用/","text":"Centos7安装chrome浏览器 安装google chrome浏览器 12wget https://dl.google.com/linux/direct/google-chrome-stable_current_x86_64.rpmyum install google-chrome-stable_current_x86_64.rpm chromedriver下载 1http://npm.taobao.org/mirrors/chromedriver/ python调用 123456chrome_options = Options()chrome_options.add_argument('--headless')chrome_options.add_argument('--no-sandbox')chrome_options.add_argument('--disable-dev-shm-usage')webdriver.Chrome(chrome_options=chrome_options)driver.get('www.baidu.com') 安装python 解压 1tar xvf Python-3.6.0a1.tar.xz 编译安装 123./configure (sudo)make(sudo)make install sudo pip命令找不到 1https://www.cnblogs.com/white-the-Alan/p/8901118.html git移除版本控制 1git rm -f -r --cached 文件名 查看centos版本 1cat /etc/redhat-release 查看空间 12df -h 查看磁盘空间du -h --max-depth=1 查看当前目录占用空间 查看端口占用 1234567891011# -a 所有# -n 显示数字# -t 显示tcp相关# -u 显示dup相关# -p 显示程序名# -l 仅显示listen的服务# -r 显示路由信息# -e 显示扩展信息，例如uid等# -s 按各个协议进行统计# -c 每隔一个固定时间，执行该netstat命令。sudo netstat -antp|grep 5000 #查看端口占用"},{"title":"docker集群","date":"2019-05-29T09:46:07.000Z","path":"2019/05/29/docker集群/","text":"Swarm安装 两台机器 初始化集群 1docker swarm init --advertise-addr 172.16.4.40 其他集群加入集群 1docker swarm join --token SWMTKN-1-6cxqgpjhpifv6cz0ns5xsqmt1c9k274lbi5pzy26zrf6dp3756-9v65biz83gka55wx0bg2y44em 172.16.4.40:2377 查看tocken，后续加入节点或管理者 1docker swarm join-token (worker|manager) 返回信息在其他机器执行 1docker swarm join --token SWMTKN-1-6cxqgpjhpifv6cz0ns5xsqmt1c9k274lbi5pzy26zrf6dp3756-08v6bjyfptsnubg6ebfsmpr79 172.16.4.40:2377 查看集群节点 1docker node ls 管理节点不运行副本 1docker node update --availability drain NODE-ID 设置服务数量 1docker service scale nginx=3 docker web管理工具 下载protainer镜像 1docker pull portainer/portainer 启动镜像 1docker run -d -p 9000:9000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v /data/portainer:/data portainer/portainer docker集群运行查看工具 下载visualizer镜像 1docker pull dockersamples/visualizer 启动镜像 1docker run -d -p 8080:8080 -v /var/run/docker.sock:/var/run/docker.sock dockersamples/visualizer"},{"title":"docker安装软件","date":"2019-05-28T08:22:25.000Z","path":"2019/05/28/docker安装软件/","text":"安装ElasticSearch及中文分词插件 配置项 1sudo sysctl -w vm.max_map_count=262144 进入镜像 1docker exec -it 容器id /bin/bash 安装插件 1elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/vES版本/elasticsearch-analysis-ik-ES版本.zip 退出并重启镜像 1exit 安装mysql数据库 docker-compose.yml文件配置123456789101112version: \"3\"services: mysql: image: mysql:5.7 restart: always environment: MYSQL_ROOT_PASSWORD: root container_name: mysql ports: - 3306:3306 volumes: - D:/db/mysql/data:/var/lib/mysql"},{"title":"实用工具","date":"2019-04-16T10:14:23.000Z","path":"2019/04/16/实用工具/","text":"Window系统工具 Listary 安装之后即可清除桌面图标，双击Ctrl就可以操作猛如虎 配置成破解pro版本 Sublime插件 Package Control 一切的基础 Pretty JSON 格式化json用的多 auto-save 自动保存 123&#123; \"auto_save_on_modified\": true&#125; MarkdownEditing 编辑 123456&#123; \"color_scheme\": \"Packages/MarkdownEditing/MarkdownEditor-Yellow.tmTheme\", \"highlight_line\": true, \"line_numbers\": true, \"mde.keep_centered\": true&#125; Idea装逼插件 Material Theme UI Lite 主题插件 Atom Material Icons 让你的图标变漂亮 Rainbow Brackets 彩虹颜色的括号 看着很舒服 敲代码效率变高 GitToolBox 查看git提交信息等 Power Mode || 炫酷编程可放礼花可屏幕颤抖 Key Promoter X 可以打印出快捷键 GsonFormatPlus 可以根据json数据直接生成java实体类（Alt+S快捷键） Maven Helper 解决maven冲突 MybatisX 可以让Mapper与Xml的sql直接跳转 RESTfulToolkit 直接根据Url跳到Controller方法（Ctrl+\\快捷键） linux防火墙命令 查看防火墙 1systemctl status firewalld 开启防火墙 1systemctl start firewalld 关闭防火墙 1systemctl stop firewalld 开启端口 1firewall-cmd --zone=public --add-port=80/tcp --permanent 删除端口 1firewall-cmd --zone=public --remove-port=80/tcp --permanent 查看某个端口 1firewall-cmd --query-port=80/tcp 查看所有端口 1firewall-cmd --list-all 重启防火墙 1firewall-cmd --reload"}]